= ADR-005: Multi-Camera Source Management

*Status:* Proposed

*Date:* 2025-12-15

== Context

.System designed for three (or more) camera sources:
* HDMI capture via MacroSilicon USB adapter
** For now... next step is to use that for an additional camera
* Direct USB microscope camera
** currently the usb capture device as no HUB used
* Raspberry Pi Camera Module (CSI) (with night vision)

.Current
* Current implementation supports single camera only.
* Camera device hardcoded in configuration.
* No source detection or switching.

.Goal
* Architecture documents stream deck interface.
* User can switch between sources.
* Each source requires different configuration.

.Potentail further cameras:
* Additional USB microscopes via powered hub
** eg thermal camera

== Decision

Defer multi-camera until single camera stable.

.When implemented:
* Auto-detect available cameras on startup
** should do now even for single camera
* Maintain separate camera service per source
* Switch active stream via API endpoint
* Show source thumbnails in UI

=== Detection Strategy

.Scan video devices on startup:
* `/dev/video0` through `/dev/video4`
* Query capabilities with v4l2
* Identify device by USB ID or driver
* Store available sources

=== Switching Approaches

.Option 1: V4L2 switching (simpler)
* Single Flask stream endpoint
* Switch camera service backend
* One stream at a time
* Lower bandwidth

.Option 2: Multiple streams (complex)
* Separate endpoint per camera
* Client-side switching
* Simultaneous preview possible
* Higher bandwidth

.Decision: 
* Start with Option 1.
* Upgrade to Option 2 if preview needed.

== Consequences

=== Positive - Deferred

* Simpler current implementation
* Single camera well-tested
* Easier deployment
* Lower resource usage

=== Negative - Deferred

* Cannot use multiple microscopes
* Manual config to switch sources
* No camera comparison
* Limited use cases

=== Positive - When Implemented

* Flexible microscope setup
* Easy source comparison
* Support different microscopes
* Stream deck interface

=== Negative - When Implemented

* More complex device management
* Camera initialization overhead
* Source switching latency
* Higher resource usage
** Could well be beyond pi zero

== Implementation Plan

.Phase 1 (current):
* Single camera via VIDEO_DEVICE env var
* Manual configuration
* Restart to switch

.Phase 2 (detection):
* Scan available cameras
* Report in /status endpoint
* UI shows available sources

.Phase 3 (switching):
* `/switch/<source>` endpoint
* Stop current camera
* Start new camera
* Update LED streaming indicator

.Phase 4 (stream deck):
* Thumbnail previews
* Click to switch
* Source status indicators

[NOTE]
====
slowly slowly catchy monkey.
====

== Stream Deck Interface

=== Features
- Preview tiles for each source (thumbnail grid)
- Click to switch active source
- Capture from any source
- Download captured images
- Source status indicators

=== UI Layout
[source]
----
┌─────────────────────────────────────┐
│ VSaGCR - Microscopy Interface        │
├─────────────────────────────────────┤
│ ┌──────┐ ┌──────┐ ┌──────┐         │
│ │HDMI  │ │ USB  │ │ Pi   │ Sources │
│ │ ▶    │ │      │ │Cam   │         │
│ └──────┘ └──────┘ └──────┘         │
├─────────────────────────────────────┤
│ [Main Preview - Active Source]      │
│                                     │
├─────────────────────────────────────┤
│ [Capture] [Record] [Switch]         │
│ Battery: ████████ 85%               │
└─────────────────────────────────────┘
----

== Configuration

Environment variables per source:

[source,yaml]
----
VIDEO_DEVICE_HDMI=/dev/video0
VIDEO_DEVICE_USB=/dev/video1
VIDEO_DEVICE_CSI=/dev/video2
----

Auto-detection overrides if devices found.
Maybe even just forgo config entirely if dynamic is good enough.

== LED Integration

Row 1 streaming indicator shows active source:
* Left side: HDMI
* Center: USB
* Right: CSI

Animations on source switch.

== Current Status

Single camera only.
Configured via VIDEO_DEVICE.
Multi-camera documented in architecture.

Waiting for:
* Production deployment experience
* User feedback on single camera (me)
* LED event queue implementation
